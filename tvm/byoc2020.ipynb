{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TVMConf-2020-BYOC link: https://gist.github.com/SrivastavaKshitij/9341a414147fbc290eff4a92b8e73acd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:42:43] /home/qzylalala/work_space/tvm/src/runtime/logging.cc:307: TVM_LOG_DEBUG enables VLOG statements in 'ir/transform.cc' up to level 1\n",
      "[10:42:43] /home/qzylalala/work_space/tvm/src/runtime/logging.cc:307: TVM_LOG_DEBUG enables VLOG statements in 'relay/ir/transform.cc' up to level 1\n",
      "/home/qzylalala/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate how BYOC annotates a Relay graph.\n",
    "\n",
    "Let's first define a simple Relay graph with supported and unsupported operators. This function includes a loop (control flow) to represent 3 convolution layers, although it's a bit weird to apply the same weights and biases many times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demo_mod():\n",
    "    # Loop\n",
    "    iter1 = relay.var(\"iter1\", shape=(), dtype=\"int32\")\n",
    "    cond = relay.less(iter1, relay.const(2, dtype=\"int32\"))\n",
    "    inc = iter1 + relay.const(1, dtype=\"int32\")\n",
    "    loop_var = relay.var(\"while_loop\")\n",
    "    \n",
    "    # Loop body\n",
    "    d1 = relay.var(\"d1\", shape=(1, 32, 56, 56), dtype=\"float32\")\n",
    "    w1 = relay.var(\"w1\", shape=(32, 32, 3, 3), dtype=\"float32\")\n",
    "    b1 = relay.var(\"b1\", shape=(32,), dtype=\"float32\")\n",
    "    conv = relay.nn.conv2d(d1, w1, strides=(1, 1), padding=(1, 1))\n",
    "    bias = relay.nn.bias_add(conv, b1)\n",
    "    relu = relay.nn.relu(bias)\n",
    "    loop_cond_out = loop_var(inc, relu, w1, b1)\n",
    "\n",
    "    conv = relay.nn.conv2d(d1, w1, strides=(1, 1), padding=(1, 1))\n",
    "    bias = relay.nn.bias_add(conv, b1)\n",
    "    relu = relay.nn.relu(bias)\n",
    "    loop_break_out = relay.reshape(relu, (1, 56, 56, 32))\n",
    "\n",
    "    ife = relay.If(cond, loop_cond_out, loop_break_out)\n",
    "\n",
    "    data = relay.var(\"data\", shape=(1, 32, 56, 56), dtype=\"float32\")\n",
    "    weight = relay.var(\"weight\", shape=(32, 32, 3, 3), dtype=\"float32\")\n",
    "    bias = relay.var(\"bias\", shape=(32,), dtype=\"float32\")\n",
    "    loop_func = relay.Function([iter1, d1, w1, b1], ife)\n",
    "\n",
    "    out = relay.Let(loop_var, loop_func, loop_var(relay.const(0, dtype=\"int32\"), data, weight, bias))\n",
    "    func = relay.Function([data, weight, bias], out)\n",
    "    mod = tvm.IRModule.from_expr(func)\n",
    "    mod = relay.transform.InferType()(mod)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "fn (%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = less(%iter1, 2 /* ty=int32 */) /* ty=bool */;\n",
      "    if (%0) {\n",
      "      %1 = nn.conv2d(%d1, %w1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %2 = nn.bias_add(%1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %3 = add(%iter1, 1 /* ty=int32 */) /* ty=int32 */;\n",
      "      %4 = nn.relu(%2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %while_loop(%3, %4, %w1, %b1) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %5 = nn.conv2d(%d1, %w1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %6 = nn.bias_add(%5, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %7 = nn.relu(%6) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      reshape(%7, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %while_loop(0 /* ty=int32 */, %data, %weight, %bias) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "} /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:43:17] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: InferType: Executing module pass with opt level: 0\n"
     ]
    }
   ],
   "source": [
    "mod = get_demo_mod()\n",
    "print(mod[\"main\"].astext(show_meta_data=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the annotation rules. As we have mentioned in the presentation, developers can specify both operator-based and pattern-based annotation rules. Here, we define the single operators `reshape` and `add` are supported. In addition, we also define two supported patterns (Conv2D - (Bias) - ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_target = \"byoc-target\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operator-based annotation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.ir.register_op_attr(\"reshape\", \"target.byoc-target\")\n",
    "def reshape(expr):\n",
    "    return True\n",
    "\n",
    "@tvm.ir.register_op_attr(\"add\", \"target.byoc-target\")\n",
    "def add(expr):\n",
    "    return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern-based annotation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pattern(with_bias=True):\n",
    "    from tvm.relay.dataflow_pattern import is_op, wildcard\n",
    "    data = wildcard()\n",
    "    weight = wildcard()\n",
    "    bias = wildcard()\n",
    "    conv = is_op(\"nn.conv2d\")(data, weight)\n",
    "    if with_bias:\n",
    "        conv_out = is_op(\"nn.bias_add\")(conv, bias)\n",
    "    else:\n",
    "        conv_out = conv\n",
    "    return is_op(\"nn.relu\")(conv_out)\n",
    "\n",
    "conv2d_bias_relu_pat = (\"byoc-target.conv2d_relu_with_bias\", make_pattern(with_bias=True))\n",
    "conv2d_relu_pat = (\"byoc-target.conv2d_relu_wo_bias\", make_pattern(with_bias=False))\n",
    "patterns = [conv2d_bias_relu_pat, conv2d_relu_pat]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform pattern-based annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "fn (%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = less(%iter1, 2 /* ty=int32 */) /* ty=bool */;\n",
      "    if (%0) {\n",
      "      %3 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %1 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %2 = nn.bias_add(%1, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%2) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %4 = add(%iter1, 1 /* ty=int32 */) /* ty=int32 */;\n",
      "      %5 = %3(%d1, %w1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %while_loop(%4, %5, %w1, %b1) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %8 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %6 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %7 = nn.bias_add(%6, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%7) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %9 = %8(%d1, %w1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      reshape(%9, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %while_loop(0 /* ty=int32 */, %data, %weight, %bias) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "} /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:44:14] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: MergeComposite: Executing function pass with opt level: 0\n",
      "[10:44:14] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: MergeComposite: Input module:\n",
      "def @main(%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = less(%iter1, 2 /* ty=int32 */) /* ty=bool */;\n",
      "    if (%0) {\n",
      "      %1 = nn.conv2d(%d1, %w1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %2 = nn.bias_add(%1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %3 = add(%iter1, 1 /* ty=int32 */) /* ty=int32 */;\n",
      "      %4 = nn.relu(%2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %while_loop(%3, %4, %w1, %b1) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %5 = nn.conv2d(%d1, %w1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %6 = nn.bias_add(%5, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %7 = nn.relu(%6) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      reshape(%7, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %while_loop(0 /* ty=int32 */, %data, %weight, %bias) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "}\n",
      "\n",
      "[10:44:14] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: MergeComposite: InferType: Executing module pass with opt level: 0\n",
      "[10:44:14] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: MergeComposite: InferType: Executing module pass with opt level: 0\n",
      "[10:44:15] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: MergeComposite: Output module:\n",
      "def @main(%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = less(%iter1, 2 /* ty=int32 */) /* ty=bool */;\n",
      "    if (%0) {\n",
      "      %3 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %1 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %2 = nn.bias_add(%1, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%2) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %4 = add(%iter1, 1 /* ty=int32 */) /* ty=int32 */;\n",
      "      %5 = %3(%d1, %w1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %while_loop(%4, %5, %w1, %b1) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %8 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %6 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %7 = nn.bias_add(%6, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%7) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %9 = %8(%d1, %w1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      reshape(%9, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %while_loop(0 /* ty=int32 */, %data, %weight, %bias) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "}\n",
      "\n",
      "[10:44:15] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: MergeComposite: InferType: Executing module pass with opt level: 0\n"
     ]
    }
   ],
   "source": [
    "mod2 = relay.transform.MergeComposite(patterns)(mod)\n",
    "print(mod2[\"main\"].astext(show_meta_data=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now all subgraphs that match the defined patterns are partitioned to \"composite functions\". In this example, we got two composite functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A composite function has two specialized attributes -- \"PartitionedFromPattern\" and \"Composite\":\n",
    "* PartitionedFromPattern: Indicate the operators in the function body.\n",
    "* Composite: Indicate the pattern name we defined.\n",
    "\n",
    "As you can imagine, this information could be useful for you to map a composite function to your accelerator in the codegen.\n",
    "Next, let's continue to apply the operator-based annotation rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "fn (%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = annotation.compiler_begin(%iter1, compiler=\"default\") /* ty=int32 */;\n",
      "    %1 = annotation.compiler_begin(2 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "    %2 = less(%0, %1) /* ty=bool */;\n",
      "    %3 = annotation.compiler_end(%2, compiler=\"default\") /* ty=bool */;\n",
      "    if (%3) {\n",
      "      %4 = annotation.compiler_begin(%iter1, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %5 = annotation.compiler_begin(1 /* ty=int32 */, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %6 = add(%4, %5) /* ty=int32 */;\n",
      "      %7 = annotation.compiler_end(%6, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %10 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %11 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %12 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %13 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %8 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %9 = nn.bias_add(%8, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%9) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %14 = %13(%10, %11, %12) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %15 = annotation.compiler_end(%14, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %16 = annotation.compiler_begin(%7, compiler=\"default\") /* ty=int32 */;\n",
      "      %17 = annotation.compiler_begin(%15, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %18 = annotation.compiler_begin(%w1, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %19 = annotation.compiler_begin(%b1, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "      %20 = %while_loop(%16, %17, %18, %19) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%20, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %23 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %24 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %25 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %26 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %21 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %22 = nn.bias_add(%21, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%22) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %27 = %26(%23, %24, %25) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %28 = annotation.compiler_end(%27, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %29 = annotation.compiler_begin(%28, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %30 = reshape(%29, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%30, compiler=\"byoc-target\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %31 = annotation.compiler_begin(0 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "  %32 = annotation.compiler_begin(%data, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "  %33 = annotation.compiler_begin(%weight, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "  %34 = annotation.compiler_begin(%bias, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "  %35 = %while_loop(%31, %32, %33, %34) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "  annotation.compiler_end(%35, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "} /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:44:32] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass AnnotateTargetFunc\n",
      "[10:44:32] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: InferType: Executing module pass with opt level: 0\n",
      "[10:44:32] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: AnnotateTargetFunc: Executing function pass with opt level: 0\n",
      "[10:44:32] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: AnnotateTargetFunc: Input module:\n",
      "def @main(%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = less(%iter1, 2 /* ty=int32 */) /* ty=bool */;\n",
      "    if (%0) {\n",
      "      %3 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %1 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %2 = nn.bias_add(%1, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%2) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %4 = add(%iter1, 1 /* ty=int32 */) /* ty=int32 */;\n",
      "      %5 = %3(%d1, %w1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %while_loop(%4, %5, %w1, %b1) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %8 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %6 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %7 = nn.bias_add(%6, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%7) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %9 = %8(%d1, %w1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      reshape(%9, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %while_loop(0 /* ty=int32 */, %data, %weight, %bias) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "}\n",
      "\n",
      "[10:44:32] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: AnnotateTargetFunc: Output module:\n",
      "def @main(%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = annotation.compiler_begin(%iter1, compiler=\"default\") /* ty=int32 */;\n",
      "    %1 = annotation.compiler_begin(2 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "    %2 = less(%0, %1) /* ty=bool */;\n",
      "    %3 = annotation.compiler_end(%2, compiler=\"default\") /* ty=bool */;\n",
      "    if (%3) {\n",
      "      %4 = annotation.compiler_begin(%iter1, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %5 = annotation.compiler_begin(1 /* ty=int32 */, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %6 = add(%4, %5) /* ty=int32 */;\n",
      "      %7 = annotation.compiler_end(%6, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %10 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %11 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %12 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %13 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %8 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %9 = nn.bias_add(%8, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%9) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %14 = %13(%10, %11, %12) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %15 = annotation.compiler_end(%14, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %16 = annotation.compiler_begin(%7, compiler=\"default\") /* ty=int32 */;\n",
      "      %17 = annotation.compiler_begin(%15, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %18 = annotation.compiler_begin(%w1, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %19 = annotation.compiler_begin(%b1, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "      %20 = %while_loop(%16, %17, %18, %19) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%20, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %23 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %24 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %25 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %26 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %21 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %22 = nn.bias_add(%21, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%22) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %27 = %26(%23, %24, %25) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %28 = annotation.compiler_end(%27, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %29 = annotation.compiler_begin(%28, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %30 = reshape(%29, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%30, compiler=\"byoc-target\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %31 = annotation.compiler_begin(0 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "  %32 = annotation.compiler_begin(%data, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "  %33 = annotation.compiler_begin(%weight, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "  %34 = annotation.compiler_begin(%bias, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "  %35 = %while_loop(%31, %32, %33, %34) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "  annotation.compiler_end(%35, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "}\n",
      "\n",
      "[10:44:32] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: AnnotateTargetFunc: InferType: Executing module pass with opt level: 0\n",
      "[10:44:32] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass InferType\n",
      "[10:44:32] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: InferType: Executing module pass with opt level: 0\n"
     ]
    }
   ],
   "source": [
    "mod3 = relay.transform.AnnotateTarget(\"byoc-target\")(mod2)\n",
    "print(mod3[\"main\"].astext(show_meta_data=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks scary! Let me make this Relay graph more readable so that we can easilty find some interesting points.\n",
    "\n",
    "* Almost all nodes in the graph are annotated with `compiler_begin` and `compiler_end` nodes. `compiler_*` nodes has an attribute `compiler` to indicate which target should this node go. In this example, it can be `default` or `byoc-target`.\n",
    "\n",
    "* Composite function calls are also annotated with `compiler=byoc-target`, indicating that this entire function can be offloaded.\n",
    " \n",
    "* We can find that some annotations can actually be merged, such as the annotations for the composite function and the following `reshape`. We use the next pass, `MergeCompilerRegion`, to merge them so that we can minimize the number of subgraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "fn (%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = annotation.compiler_begin(%iter1, compiler=\"default\") /* ty=int32 */;\n",
      "    %1 = annotation.compiler_begin(2 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "    %2 = less(%0, %1) /* ty=bool */;\n",
      "    %3 = annotation.compiler_end(%2, compiler=\"default\") /* ty=bool */;\n",
      "    if (%3) {\n",
      "      %4 = annotation.compiler_begin(%iter1, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %5 = annotation.compiler_begin(1 /* ty=int32 */, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %6 = add(%4, %5) /* ty=int32 */;\n",
      "      %7 = annotation.compiler_end(%6, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %10 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %11 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %12 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %13 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %8 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %9 = nn.bias_add(%8, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%9) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %14 = %13(%10, %11, %12) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %15 = annotation.compiler_end(%14, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %16 = annotation.compiler_begin(%7, compiler=\"default\") /* ty=int32 */;\n",
      "      %17 = annotation.compiler_begin(%15, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %18 = annotation.compiler_begin(%w1, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %19 = annotation.compiler_begin(%b1, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "      %20 = %while_loop(%16, %17, %18, %19) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%20, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %23 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %24 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %25 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %26 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %21 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %22 = nn.bias_add(%21, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%22) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %27 = %26(%23, %24, %25) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %28 = reshape(%27, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%28, compiler=\"byoc-target\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %29 = annotation.compiler_begin(0 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "  %30 = annotation.compiler_begin(%data, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "  %31 = annotation.compiler_begin(%weight, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "  %32 = annotation.compiler_begin(%bias, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "  %33 = %while_loop(%29, %30, %31, %32) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "  annotation.compiler_end(%33, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "} /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:44:45] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass MergeCompilerRegions\n",
      "[10:44:45] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: MergeCompilerRegions: Executing function pass with opt level: 0\n",
      "[10:44:45] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: MergeCompilerRegions: Input module:\n",
      "def @main(%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = annotation.compiler_begin(%iter1, compiler=\"default\") /* ty=int32 */;\n",
      "    %1 = annotation.compiler_begin(2 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "    %2 = less(%0, %1) /* ty=bool */;\n",
      "    %3 = annotation.compiler_end(%2, compiler=\"default\") /* ty=bool */;\n",
      "    if (%3) {\n",
      "      %4 = annotation.compiler_begin(%iter1, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %5 = annotation.compiler_begin(1 /* ty=int32 */, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %6 = add(%4, %5) /* ty=int32 */;\n",
      "      %7 = annotation.compiler_end(%6, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %10 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %11 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %12 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %13 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %8 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %9 = nn.bias_add(%8, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%9) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %14 = %13(%10, %11, %12) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %15 = annotation.compiler_end(%14, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %16 = annotation.compiler_begin(%7, compiler=\"default\") /* ty=int32 */;\n",
      "      %17 = annotation.compiler_begin(%15, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %18 = annotation.compiler_begin(%w1, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %19 = annotation.compiler_begin(%b1, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "      %20 = %while_loop(%16, %17, %18, %19) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%20, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %23 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %24 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %25 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %26 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %21 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %22 = nn.bias_add(%21, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%22) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %27 = %26(%23, %24, %25) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %28 = annotation.compiler_end(%27, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %29 = annotation.compiler_begin(%28, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %30 = reshape(%29, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%30, compiler=\"byoc-target\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %31 = annotation.compiler_begin(0 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "  %32 = annotation.compiler_begin(%data, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "  %33 = annotation.compiler_begin(%weight, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "  %34 = annotation.compiler_begin(%bias, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "  %35 = %while_loop(%31, %32, %33, %34) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "  annotation.compiler_end(%35, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "}\n",
      "\n",
      "[10:44:45] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: MergeCompilerRegions: Output module:\n",
      "def @main(%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = annotation.compiler_begin(%iter1, compiler=\"default\") /* ty=int32 */;\n",
      "    %1 = annotation.compiler_begin(2 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "    %2 = less(%0, %1) /* ty=bool */;\n",
      "    %3 = annotation.compiler_end(%2, compiler=\"default\") /* ty=bool */;\n",
      "    if (%3) {\n",
      "      %4 = annotation.compiler_begin(%iter1, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %5 = annotation.compiler_begin(1 /* ty=int32 */, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %6 = add(%4, %5) /* ty=int32 */;\n",
      "      %7 = annotation.compiler_end(%6, compiler=\"byoc-target\") /* ty=int32 */;\n",
      "      %10 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %11 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %12 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %13 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %8 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %9 = nn.bias_add(%8, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%9) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %14 = %13(%10, %11, %12) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %15 = annotation.compiler_end(%14, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %16 = annotation.compiler_begin(%7, compiler=\"default\") /* ty=int32 */;\n",
      "      %17 = annotation.compiler_begin(%15, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %18 = annotation.compiler_begin(%w1, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %19 = annotation.compiler_begin(%b1, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "      %20 = %while_loop(%16, %17, %18, %19) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%20, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      %23 = annotation.compiler_begin(%d1, compiler=\"byoc-target\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %24 = annotation.compiler_begin(%w1, compiler=\"byoc-target\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "      %25 = annotation.compiler_begin(%b1, compiler=\"byoc-target\") /* ty=Tensor[(32), float32] */;\n",
      "      %26 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "        %21 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        %22 = nn.bias_add(%21, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "        nn.relu(%22) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "      } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %27 = %26(%23, %24, %25) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %28 = reshape(%27, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "      annotation.compiler_end(%28, compiler=\"byoc-target\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %29 = annotation.compiler_begin(0 /* ty=int32 */, compiler=\"default\") /* ty=int32 */;\n",
      "  %30 = annotation.compiler_begin(%data, compiler=\"default\") /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "  %31 = annotation.compiler_begin(%weight, compiler=\"default\") /* ty=Tensor[(32, 32, 3, 3), float32] */;\n",
      "  %32 = annotation.compiler_begin(%bias, compiler=\"default\") /* ty=Tensor[(32), float32] */;\n",
      "  %33 = %while_loop(%29, %30, %31, %32) /* ty=Tensor[(1, 56, 56, 32), float32] */;\n",
      "  annotation.compiler_end(%33, compiler=\"default\") /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "}\n",
      "\n",
      "[10:44:45] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: MergeCompilerRegions: InferType: Executing module pass with opt level: 0\n",
      "[10:44:45] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass InferType\n",
      "[10:44:45] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: InferType: Executing module pass with opt level: 0\n"
     ]
    }
   ],
   "source": [
    "mod4 = relay.transform.MergeCompilerRegions()(mod3)\n",
    "print(mod4[\"main\"].astext(show_meta_data=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that now the `add` and the composite function call in the loop body share the same set of annotation nodes. i.e., the consecutive `compiler_end` and `compiler_begin` nodes are removed.\n",
    "\n",
    "Finally, let's partition this graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass FlattenNestedTuples\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: FlattenNestedTuples: Executing module pass with opt level: 0\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: FlattenNestedTuples: InferType: Executing module pass with opt level: 0\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass RemoveDefaultAnnotations\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: RemoveDefaultAnnotations: Executing module pass with opt level: 0\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: RemoveDefaultAnnotations: InferType: Executing module pass with opt level: 0\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass PartitionGraph\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: PartitionGraph: Executing module pass with opt level: 0\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: PartitionGraph: InferType: Executing module pass with opt level: 0\n",
      "[10:44:53] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: PartitionGraph: InferType: Executing module pass with opt level: 0\n",
      "[10:44:54] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: PartitionGraph: InferType: Executing module pass with opt level: 0\n",
      "[10:44:54] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: PartitionGraph: InferType: Executing module pass with opt level: 0\n",
      "[10:44:54] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass NameMangleExtFuncs\n",
      "[10:44:54] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: NameMangleExtFuncs: Executing module pass with opt level: 0\n",
      "[10:44:54] /home/qzylalala/work_space/tvm/src/ir/transform.cc:440: Running pass InferType\n",
      "[10:44:54] /home/qzylalala/work_space/tvm/src/ir/transform.cc:379: InferType: Executing module pass with opt level: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#[version = \"0.0.5\"]\n",
      "fn (%data: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %weight: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %bias: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  let %while_loop: fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */ = fn (%iter1: int32 /* ty=int32 */, %d1: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %w1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %b1: Tensor[(32), float32] /* ty=Tensor[(32), float32] */) -> Tensor[(1, 56, 56, 32), float32] {\n",
      "    %0 = less(%iter1, 2 /* ty=int32 */) /* ty=bool */;\n",
      "    if (%0) {\n",
      "      %1 = @tvmgen_default_byoc_target_main_0(%iter1) /* ty=int32 */;\n",
      "      %2 = @tvmgen_default_byoc_target_main_2(%d1, %w1, %b1) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "      %while_loop(%1, %2, %w1, %b1) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    } else {\n",
      "      @tvmgen_default_byoc_target_main_5(%d1, %w1, %b1) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "    }\n",
      "  } /* ty=fn (int32, Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */;\n",
      "  %while_loop(0 /* ty=int32 */, %data, %weight, %bias) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "} /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */\n"
     ]
    }
   ],
   "source": [
    "mod5 = relay.transform.PartitionGraph()(mod4)\n",
    "print(mod5[\"main\"].astext(show_meta_data=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's much clean now, right? We can see that 3 subgraphs have been partitioned for `byoc-target`. Let's see dive into each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvmgen_default_byoc_target_main_0: \n",
      "#[version = \"0.0.5\"]\n",
      "fn (%byoc-target_0_i0: int32 /* ty=int32 */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_0\") -> int32 {\n",
      "  add(%byoc-target_0_i0, 1 /* ty=int32 */) /* ty=int32 */\n",
      "} /* ty=fn (int32) -> int32 */\n",
      "==================\n",
      "tvmgen_default_byoc_target_main_2: \n",
      "#[version = \"0.0.5\"]\n",
      "fn (%byoc-target_2_i0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %byoc-target_2_i1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %byoc-target_2_i2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_2\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "  %2 = fn (%FunctionVar_1_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "    %0 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "    %1 = nn.bias_add(%0, %FunctionVar_1_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "    nn.relu(%1) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "  %2(%byoc-target_2_i0, %byoc-target_2_i1, %byoc-target_2_i2) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "} /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */\n",
      "==================\n",
      "tvmgen_default_byoc_target_main_5: \n",
      "#[version = \"0.0.5\"]\n",
      "fn (%byoc-target_5_i0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %byoc-target_5_i1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %byoc-target_5_i2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, Compiler=\"byoc-target\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_byoc_target_main_5\") -> Tensor[(1, 56, 56, 32), float32] {\n",
      "  %2 = fn (%FunctionVar_0_0: Tensor[(1, 32, 56, 56), float32] /* ty=Tensor[(1, 32, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(32, 32, 3, 3), float32] /* ty=Tensor[(32, 32, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(32), float32] /* ty=Tensor[(32), float32] */, PartitionedFromPattern=\"nn.conv2d_nn.bias_add_nn.relu_\", Composite=\"byoc-target.conv2d_relu_with_bias\") -> Tensor[(1, 32, 56, 56), float32] {\n",
      "    %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "    %1 = nn.bias_add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "    nn.relu(%1) /* ty=Tensor[(1, 32, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 32, 56, 56), float32] */;\n",
      "  %3 = %2(%byoc-target_5_i0, %byoc-target_5_i1, %byoc-target_5_i2) /* ty=Tensor[(1, 32, 56, 56), float32] */;\n",
      "  reshape(%3, newshape=[1, 56, 56, 32]) /* ty=Tensor[(1, 56, 56, 32), float32] */\n",
      "} /* ty=fn (Tensor[(1, 32, 56, 56), float32], Tensor[(32, 32, 3, 3), float32], Tensor[(32), float32]) -> Tensor[(1, 56, 56, 32), float32] */\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "for name in [\"tvmgen_default_byoc_target_main_0\", \"tvmgen_default_byoc_target_main_2\", \"tvmgen_default_byoc_target_main_5\"]:\n",
    "    print(\"%s: \" % name)\n",
    "    print(mod5[name].astext(show_meta_data=False))\n",
    "    print(\"==================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each partitioned function will be sent to the \"byoc-target\" codegen for code generation. As a result, you can imagine that the customized codegen only needs to consider the subgraphs without worrying about rest parts of the graph. In this example, it also means that the customzied codegen doesn't have to worry abou the control flow (nice!\n",
    "\n",
    "In the rest part of this demo, we are going to build a real world SSD model with the TensorRT BYOC integration, which is already available in the upstream TVM so you are welcome to try it by yourself. Specifically, we will build a Gluon CV SSD-ResNet50 model with TensorRT.\n",
    "\n",
    "Please note that in order to run this example by yourself, you need to set up TensorRT in your environment and build the TVM with TensorRT runtime. You can refer to the TVM TensorRT tutorial for detail instructions: https://tvm.apache.org/docs/deploy/tensorrt.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
